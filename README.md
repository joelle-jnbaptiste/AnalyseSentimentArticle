# Comparaison des approches de classification et d√©marche MLOps

_Auteur : JEAN BAPTISTE Jo√´lle_  
_Date : Avril 2025_

---

## Table des mati√®res

- [Introduction](#introduction)
- [Pr√©sentation et comparaison des mod√®les](#pr√©sentation-et-comparaison-des-mod√®les)
  - [Mod√®le sur mesure simple](#mod√®le-sur-mesure-simple)
  - [Mod√®le sur mesure avanc√©](#mod√®le-sur-mesure-avanc√©)
  - [Mod√®le avanc√© BERT](#mod√®le-avanc√©-bert)
- [D√©marche MLOps mise en ≈ìuvre](#d√©marche-mlops-mise-en-≈ìuvre)
  - [Principes g√©n√©raux](#principes-g√©n√©raux)
  - [Cycle MLOps du projet](#cycle-mlops-du-projet)
  - [Suivi des exp√©rimentations](#suivi-des-exp√©rimentations)
  - [Tests unitaires](#tests-unitaires)
  - [Architecture applicative d√©ploy√©e sur Azure](#architecture-applicative-d√©ploy√©e-sur-azure)
  - [D√©ploiement de l‚ÄôAPI](#d√©ploiement-de-lapi)
  - [Interface front de test (locale)](#interface-front-de-test-locale)
  - [Monitoring et alertes](#monitoring-et-alertes)
- [Proposition de d√©marche pour l'am√©lioration continue du mod√®le](#proposition-de-d√©marche-pour-lam√©lioration-continue-du-mod√®le)
- [Conclusion](#conclusion)

---

### üîó Liens vers les d√©p√¥ts du projet

- üíª **Backend (API FastAPI + mod√®le TFLite + d√©ploiement Azure)**  
  [https://github.com/joelle-jnbaptiste/Analyse_Sentiments](https://github.com/joelle-jnbaptiste/Analyse_Sentiments)

- üß™ **Frontend (Interface de test locale en Streamlit)**  
  [https://github.com/joelle-jnbaptiste/FrontAnalyseSentiment](https://github.com/joelle-jnbaptiste/FrontAnalyseSentiment)

---

## Introduction

Dans le cadre de ce projet, nous avons con√ßu et compar√© plusieurs approches de classification de sentiments afin d'√©valuer leur pertinence en situation r√©elle.  
L‚Äôobjectif √©tait double : √©valuer les performances de diff√©rents types de mod√®les ‚Äî du plus simple au plus avanc√© ‚Äî et mettre en place une d√©marche MLOps compl√®te garantissant un suivi, une reproductibilit√© et une am√©lioration continue du mod√®le en production.

Trois approches ont √©t√© √©tudi√©es :

- Un mod√®le sur mesure simple, bas√© sur des techniques classiques de vectorisation et de classification.
- Un mod√®le sur mesure avanc√©, int√©grant des m√©thodes d‚Äôapprentissage plus complexes.
- Un mod√®le avanc√© bas√© sur BERT, une architecture de type Transformer pr√©-entra√Æn√©e, convertie ici au format TFLite pour faciliter son d√©ploiement.

Pour accompagner ces exp√©rimentations, une architecture orient√©e MLOps a √©t√© mise en place, int√©grant le tracking des mod√®les via MLflow, le d√©ploiement via Docker et Azure Container Apps, ainsi que le monitoring et les alertes via Azure Application Insights.

Ce document pr√©sente la d√©marche, les r√©sultats de comparaison des mod√®les et la mani√®re dont les principes MLOps ont √©t√© appliqu√©s √† ce projet.

---

## Pr√©sentation et comparaison des mod√®les

### Mod√®le sur mesure simple

Description : TF-IDF + r√©gression logistique  
**Avantages** : rapide, simple √† mettre en place, interpr√©table  
**Inconv√©nients** : faible g√©n√©ralisation, moins performant

### Mod√®le sur mesure avanc√©

Exemple : TF-IDF + Random Forest, ou r√©seau de neurones simple  
**Avantages** : meilleure performance, prise en compte non-lin√©arit√©  
**Inconv√©nients** : plus de calcul, tuning plus complexe

### Mod√®le avanc√© BERT

Utilisation de `DistilBERT` avec conversion en TFLite.  
**Avantages** : tr√®s bonne pr√©cision, transfert learning  
**Inconv√©nients** : lourd, plus difficile √† d√©ployer

![Tableau comparatif des mod√®les](images/comparaison_modeles.png)

---

## D√©marche MLOps mise en ≈ìuvre

### Principes g√©n√©raux

Dans ce projet, l‚Äôapproche MLOps permet de structurer le cycle de vie du mod√®le de classification de sentiment, de l‚Äôexp√©rimentation jusqu‚Äôau suivi en production.

Les objectifs sont les suivants :

- **Reproductibilit√©** : pouvoir relancer les entra√Ænements et obtenir les m√™mes r√©sultats
- **Tra√ßabilit√©** : conserver l‚Äôhistorique des essais, des m√©triques et des versions de mod√®les
- **Fiabilit√©** : tester automatiquement les composants critiques
- **Automatisation** : d√©ploiement reproductible via Docker, h√©bergement cloud
- **Observabilit√©** : supervision en production, alertes sur d√©rives ou erreurs
- **Am√©lioration continue** : collecte de feedbacks utilisateurs pour affiner le mod√®le

Ces principes ont guid√© la mise en ≈ìuvre technique d√©crite dans les sous-sections suivantes.

### Cycle MLOps du projet

Le sch√©ma suivant illustre la **vision globale du cycle MLOps** mise en place dans le projet.  
On y retrouve les phases principales allant du d√©veloppement √† la mise en production, en passant par la validation, la surveillance et une proposition de boucle d'am√©lioration continue.

![Cycle MLOps](images/cycleMLOps.png)

### Suivi des exp√©rimentations

Toutes les exp√©rimentations ont √©t√© suivies √† l‚Äôaide de **MLflow**, un outil open source de gestion du cycle de vie des mod√®les de machine learning.

Nous avons utilis√© **MLflow Tracking** pour enregistrer :

- Les **hyperparam√®tres** (par exemple `max_features`, `model_type`, etc.)
- Les **scores de performance** (accuracy, F1-score, etc.)
- Les **art√©facts** tels que les mod√®les entra√Æn√©s, les tokenizers, et les logs
- Les **tags** permettant de regrouper ou filtrer des essais par type de mod√®le ou objectif

Chaque ex√©cution (`run`) est associ√©e √† un identifiant unique, une date, et une version du code, ce qui permet de revenir en arri√®re ou de reproduire un r√©sultat √† tout moment.

L‚Äôinterface web de MLflow a √©galement permis de comparer visuellement les r√©sultats des diff√©rents mod√®les :

- Comparaison de courbes de performances
- Tri des runs par m√©triques
- R√©cup√©ration directe des mod√®les les plus performants

Voici un exemple de capture d‚Äô√©cran d‚Äôun run MLflow :

![Exemple MLflow Tracking](images/mlflow_tracking.png)

Cette tra√ßabilit√© a √©t√© essentielle pour identifier la meilleure approche √† d√©ployer en production.

### Versionnement et stockage des mod√®les

Dans ce projet, le **versionnement du code source et du mod√®le** a √©t√© assur√© uniquement via **Git**, ce qui s'est av√©r√© suffisant gr√¢ce √† la l√©g√®ret√© du mod√®le final utilis√© (format `.tflite`).

Contrairement √† une architecture MLOps compl√®te avec stockage cloud (Blob Storage, S3, etc.), nous avons choisi une approche plus simple mais efficace : le mod√®le final est int√©gr√© directement dans le d√©p√¥t du projet, aux c√¥t√©s du tokenizer.

Ce choix est rendu possible gr√¢ce √† l‚Äôutilisation de **TensorFlow Lite**, qui g√©n√®re un mod√®le compress√© facile √† embarquer dans une API ou un conteneur Docker, sans compromettre les performances.

Les exp√©rimentations ont quant √† elles √©t√© suivies via **MLflow**, mais **le stockage et le d√©ploiement du mod√®le retenu** reposent uniquement sur le versionnement Git.  
Cela garantit une bonne tra√ßabilit√© tout en limitant la complexit√© d‚Äôinfrastructure.

**R√©sum√©** :

- ‚úÖ Code versionn√© avec Git
- ‚úÖ Mod√®le `.tflite` lightweight versionn√© dans le d√©p√¥t
- ‚úÖ MLflow utilis√© pour la comparaison des exp√©rimentations, pas pour le d√©ploiement

---

### Tests unitaires

Des tests unitaires ont √©t√© mis en place afin de garantir la fiabilit√© du mod√®le de classification avant sa mise en production. Ces tests ont √©t√© con√ßus pour valider les points critiques du pipeline d'inf√©rence. Ils sont regroup√©s dans un r√©pertoire `tests/` et ex√©cut√©s avec **pytest**.

Trois tests principaux ont √©t√© d√©finis :

1. **Test de pr√©diction positive**  
   Ce test v√©rifie que le mod√®le est capable d‚Äôidentifier correctement un texte clairement positif.  
   Il confirme que la pr√©diction retourn√©e est bien `1` et que la sortie respecte le bon format (`list` contenant un `int`).

2. **Test de pr√©diction n√©gative**  
   Similaire au test pr√©c√©dent, il v√©rifie que le mod√®le retourne `0` pour une phrase n√©gative.  
   Il permet de s‚Äôassurer du comportement attendu sur les cas simples.

3. **Test de robustesse sur un lot de phrases**  
   Le mod√®le est test√© sur plusieurs exemples positifs et n√©gatifs, avec une v√©rification du taux de bonnes pr√©dictions.  
   Ce test permet de valider la stabilit√© du mod√®le sur des entr√©es vari√©es.

Ces tests sont automatiquement ex√©cut√©s √† chaque **pull request** via une **action GitHub**. Cela permet de valider les modifications avant int√©gration.

Bien que la version gratuite de GitHub ne permette pas de bloquer une fusion en cas d‚Äô√©chec, cette pratique est essentielle en contexte professionnel, o√π les workflows peuvent √™tre configur√©s comme **bloquants** (CI obligatoire avant merge).

Voici deux captures d'√©cran illustrant cette int√©gration :

#### Aper√ßu des ex√©cutions de workflow GitHub Actions

![Aper√ßu GitHub Actions](images/githubAction.png)

#### Exemple de rapport de tests ex√©cut√©s avec `pytest`

![Rapport pytest GitHub](images/githubTest.png)

Cette strat√©gie permet de s√©curiser la phase de d√©veloppement, de d√©tecter rapidement les erreurs, et de favoriser une meilleure qualit√© de code dans le temps.

---

### Architecture applicative d√©ploy√©e sur Azure

Le diagramme suivant pr√©sente les diff√©rents composants du projet et leur interaction entre la **partie locale (frontend Streamlit)** et l‚Äô**infrastructure cloud (API d√©ploy√©e, Application Insights, alerting)**.

On y visualise :

- Le fonctionnement du front local en interaction avec l‚ÄôAPI (`/predict` et `/feedback`)
- Le traitement de ces requ√™tes via le container Azure
- La journalisation des feedbacks dans Application Insights
- Le syst√®me d‚Äôalerte d√©clench√© en cas d‚Äôerreurs r√©p√©t√©es

![Architecture Azure](images/application.png)

---

### D√©ploiement de l‚ÄôAPI

L‚ÄôAPI a √©t√© d√©velopp√©e avec **FastAPI**, un framework l√©ger et rapide pour cr√©er des services web en Python. Elle expose deux endpoints : `/predict` pour la pr√©diction de sentiment, et `/feedback` pour la collecte de retour utilisateur.  
Une fois test√©e en local, elle a √©t√© conteneuris√©e puis d√©ploy√©e sur Azure.

#### Conteneurisation avec Docker

L‚Äôensemble du projet (API, mod√®le TFLite, tokenizer) est empaquet√© dans une image Docker.  
Cela garantit une ex√©cution reproductible en local comme en cloud. Les d√©pendances sont d√©finies dans un fichier `requirements-api.txt`.

Avant de proc√©der au d√©ploiement sur Azure, il est possible de tester l‚ÄôAPI **en local** √† l‚Äôaide des commandes suivantes :

```bash
# Construction de l‚Äôimage Docker
docker build -t sentiment-api .

# Lancement du conteneur localement
docker run -p 8000:8000 sentiment-api
```

Une fois le conteneur lanc√©, l‚ÄôAPI est accessible √† l‚Äôadresse suivante dans le navigateur :

```
http://localhost:8000/docs
```

Cela permet de tester les endpoints `/predict` et `/feedback` via Swagger, comme si elle √©tait d√©j√† en ligne.

L‚Äôimage est ensuite pouss√©e dans un **container registry Azure** et d√©ploy√©e automatiquement via GitHub Actions.

![Pipeline de d√©ploiement GitHub](images/pipelineDeploiment.png)

---

#### D√©ploiement sur Azure Container Apps

L‚Äôimage est d√©ploy√©e dans **Azure Container Apps**, un service manag√© qui permet d‚Äôex√©cuter l‚ÄôAPI sans g√©rer de VM.  
Cette solution assure la scalabilit√© automatique, un monitoring natif et une int√©gration facile avec Application Insights.

![Instance Azure Container App](images/containerApp.png)

#### Endpoints disponibles et testables

Une fois l‚ÄôAPI d√©ploy√©e, elle est accessible publiquement et peut √™tre test√©e via l‚Äôinterface Swagger g√©n√©r√©e automatiquement par FastAPI.

Voici les endpoints disponibles :

- `/predict` : re√ßoit une cha√Æne de caract√®res et retourne une pr√©diction (`0` ou `1`)
- `/feedback` : enregistre le feedback utilisateur sur une pr√©diction

![Swagger UI FastAPI](images/swagger.png)

#### Exemple d‚Äôappel √† `/predict`

```json
{
  "text": "string"
}
```

![Test de l‚Äôendpoint predict](images/endpointPredict.png)

#### Exemple d‚Äôappel √† `/feedback`

```json
{
  "texte": "string",
  "prediction": 0,
  "feedback_correct": true
}
```

![Test de l‚Äôendpoint feedback](images/endpointFeedback.png)

Ce d√©ploiement permet de rendre le mod√®le disponible √† des utilisateurs externes, tout en facilitant la supervision et les mises √† jour gr√¢ce √† la conteneurisation et √† l‚Äôautomatisation des workflows.

---

### Interface front de test (locale)

Pour permettre une √©valuation simple de l‚ÄôAPI sans passer par des outils externes, une interface utilisateur l√©g√®re a √©t√© d√©velopp√©e avec **Streamlit**.

Ce front-end n‚Äôest pas d√©ploy√© sur le cloud, mais peut √™tre lanc√© localement pour :

- Tester le comportement du mod√®le (`/predict`)
- Visualiser la pr√©diction sous forme lisible (positif/n√©gatif)
- Soumettre un retour utilisateur (`/feedback`)
- Envoyer les feedbacks en un clic

#### Fonctionnement

L‚Äôutilisateur entre un message libre dans un champ texte, clique sur "Analyser le sentiment", et obtient une r√©ponse imm√©diate.  
Il peut ensuite valider ou invalider la pr√©diction via une interface radio + bouton, ce qui d√©clenche l‚Äôappel au second endpoint.

Voici quelques captures d‚Äô√©cran illustrant le parcours :

- Interface au d√©marrage :

  ![Formulaire vide](images/appBlank.png)

- Exemple de pr√©diction n√©gative avec retour utilisateur :

  ![Pr√©diction n√©gative](images/appNegatif.png)  
  ![Feedback envoy√©](images/appFeedback.png)

- Exemple de pr√©diction positive :

  ![Pr√©diction positive](images/appPositif.png)

#### Lancement local

Le front est accessible uniquement localement.  
Pour le d√©marrer :

```bash
streamlit run app.py
```

Cela ouvre automatiquement l‚Äôapplication dans le navigateur √† l‚Äôadresse suivante :

```
http://localhost:8501
```

Il est √©galement possible de personnaliser les endpoints dans le code pour pointer vers une instance distante, mais ce front a √©t√© con√ßu principalement √† des fins de test.

**R√©sum√© :**

- D√©velopp√© avec Streamlit
- Permet de tester `/predict` et `/feedback`
- Lancement simple en local
- Non d√©ploy√© dans le cloud

---

### Monitoring et alertes

Une fois l‚ÄôAPI d√©ploy√©e dans Azure Container Apps, il est essentiel d‚Äôassurer un suivi en production pour d√©tecter les erreurs, suivre l‚Äôusage, et alimenter une boucle de retour pour am√©liorer le mod√®le.

Le projet utilise **Azure Application Insights**, int√©gr√© via la biblioth√®que `azure-monitor-opentelemetry` dans le backend FastAPI.

#### Logs et suivi applicatif

√Ä chaque appel √† l‚ÄôAPI, des logs personnalis√©s sont envoy√©s √† Application Insights, notamment lors de la r√©ception de feedback utilisateur.  
Ces logs incluent les champs essentiels : texte, pr√©diction retourn√©e, retour utilisateur, erreurs √©ventuelles, etc.

Voici un aper√ßu de l‚Äôenvironnement Application Insights :

![Application Insights](images/AppInsight.png)

Des tableaux de bord peuvent √™tre cr√©√©s pour visualiser l'activit√© des endpoints, les fr√©quences d‚Äôappels et les erreurs :

![Dashboard personnalis√© Azure Workbook](images/workbook1.png)  
![Autre vue de suivi](images/workbook2.png)  
![Suivi d√©taill√© d‚Äôun feedback](images/workbook3.png)  
![Exploration des donn√©es via workbook](images/workbook4.png)

#### Mise en place des alertes

Des **r√®gles d‚Äôalerte** sont configur√©es √† partir des logs collect√©s. Cela permet d‚Äô√™tre notifi√© si une anomalie est d√©tect√©e.

Exemples de r√®gles mises en place :

- Erreurs fr√©quentes sur l‚ÄôAPI
- Trop grand nombre de feedbacks n√©gatifs sur une p√©riode donn√©e

Exemples de notifications envoy√©es par mail :

![Email d'alerte - 1](images/emailAlert.png)  
![Email d'alerte - 2](images/emailAlert2.png)  
![Email d'alerte - 3](images/emailAlert3.png)

Exemples de r√®gles dans Azure :

![Configuration alerte 1](images/warning1.png)  
![Configuration alerte 2](images/warning2.png)

#### Cas d‚Äôusage : boucle de feedback

Chaque retour utilisateur est consign√© et analysable. Ces donn√©es permettent :

- D‚Äôidentifier des pr√©dictions incorrectes
- D‚Äôalimenter un futur jeu de donn√©es pour l‚Äôam√©lioration du mod√®le
- De d√©clencher des retrainings cibl√©s

Cela alimente une **d√©marche de model monitoring** et d'am√©lioration continue.

**R√©sum√© :**

- Logs envoy√©s automatiquement vers Azure Application Insights
- Tableaux de bord de suivi en temps r√©el (Workbook)
- Alertes configur√©es en cas de d√©rives
- Notifications email op√©rationnelles
- Donn√©es pr√™tes pour l‚Äôanalyse et l‚Äôam√©lioration du mod√®le

---

### Proposition de d√©marche pour l'am√©lioration continue du mod√®le

Bien que le projet n‚Äôint√®gre pas encore de pipeline automatis√© de r√©entra√Ænement, une **d√©marche d‚Äôam√©lioration continue** pourrait √™tre mise en place √† partir des √©l√©ments d√©j√† existants (API en production, retours utilisateurs, logs centralis√©s).

Voici les grandes √©tapes d‚Äôune telle strat√©gie :

#### 1. Collecte automatis√©e des feedbacks

L‚ÄôAPI `/feedback` permet d√©j√† de r√©cup√©rer l‚Äô√©valuation de la pr√©diction par l‚Äôutilisateur (feedback correct ou non).  
Ces donn√©es peuvent √™tre stock√©es dans une base d√©di√©e ou extraites r√©guli√®rement depuis Application Insights.

#### 2. Cr√©ation d‚Äôun jeu de donn√©es compl√©mentaire

Les retours utilisateurs o√π la pr√©diction √©tait incorrecte (feedback n√©gatif) peuvent √™tre utilis√©s pour enrichir le jeu d‚Äôentra√Ænement.  
Cette base peut √™tre filtr√©e, nettoy√©e, puis int√©gr√©e √† une version 2 du dataset.

#### 3. R√©entra√Ænement p√©riodique

Un pipeline de r√©entra√Ænement pourrait √™tre ex√©cut√© de mani√®re :

- Manuelle (ex. via script Python d√©clench√© chaque mois)
- Ou automatis√©e (ex. via GitHub Actions ou Azure Machine Learning)

L‚Äôid√©e serait de recharger le mod√®le avec :

- Le dataset initial
- - les retours utilisateurs corrig√©s
- - √©ventuellement des pond√©rations pour les cas difficiles

#### 4. R√©√©valuation et tra√ßabilit√©

Chaque nouveau mod√®le peut √™tre :

- Compar√© √† l'ancien via MLflow
- Versionn√© avec un identifiant clair
- Test√© automatiquement avant mise en production

#### 5. D√©ploiement contr√¥l√©

Une fois valid√©, le mod√®le mis √† jour peut √™tre d√©ploy√© via Docker + CI/CD, comme dans la version actuelle.  
Un tag (`v2`, `v3`, etc.) permettrait de suivre les √©volutions dans le temps.

#### 6. Boucle d‚Äôapprentissage continue

Ce m√©canisme permettrait d‚Äôimpl√©menter une **boucle vertueuse**, o√π :

- L‚Äôusage r√©el de l‚ÄôAPI alimente le dataset
- Le mod√®le est continuellement ajust√©
- La performance en production s‚Äôam√©liore au fil du temps

Cette strat√©gie constitue une base solide pour aller vers une vraie d√©marche de **‚Äúcontinuous learning‚Äù**, souvent recherch√©e dans les contextes industriels ou √† forte √©volution s√©mantique.

---

## Conclusion

Ce projet de classification de sentiments s‚Äôest appuy√© sur une approche structur√©e m√™lant data science, d√©veloppement API, et bonnes pratiques de MLOps.

Trois mod√®les ont √©t√© test√©s, compar√©s et √©valu√©s afin d‚Äôidentifier la solution la plus performante et la plus l√©g√®re √† d√©ployer (un mod√®le DistilBERT export√© en TensorFlow Lite).  
Un soin particulier a √©t√© apport√© √† la **tra√ßabilit√© des exp√©rimentations**, au **versionnement**, √† la **mise en production via Docker et Azure**, ainsi qu‚Äô√† la **mise en place de tests automatis√©s** pour garantir la qualit√© du code.

L‚Äô**int√©gration d‚ÄôAzure Application Insights** a permis un suivi fin des appels √† l‚ÄôAPI, avec des alertes configurables, offrant ainsi les bases d‚Äôune v√©ritable observabilit√© en production.

Enfin, une **d√©marche projet√©e d‚Äôam√©lioration continue** a √©t√© esquiss√©e, afin d‚Äôexploiter les feedbacks utilisateurs collect√©s et d‚Äôenvisager des mises √† jour futures du mod√®le de mani√®re contr√¥l√©e.

Ce travail montre qu‚Äôil est possible, m√™me avec des ressources limit√©es, de mettre en place une cha√Æne de traitement de machine learning compl√®te, fiable, et pr√™te pour des √©volutions futures en production.
